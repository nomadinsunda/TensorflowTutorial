{"cells":[{"cell_type":"markdown","metadata":{"id":"ISubpr_SSsiM"},"source":["##### Copyright 2020 The TensorFlow Authors.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","execution":{"iopub.execute_input":"2021-10-26T01:29:42.171133Z","iopub.status.busy":"2021-10-26T01:29:42.170595Z","iopub.status.idle":"2021-10-26T01:29:42.174330Z","shell.execute_reply":"2021-10-26T01:29:42.174660Z"},"id":"3jTMb1dySr3V"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"6DWfyNThSziV"},"source":["# Introduction to modules, layers, and models\n","\n","<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_modules\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_modules.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/intro_to_modules.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"v0DdlfacAdTZ"},"source":["To do machine learning in TensorFlow, you are likely to need to define, save, and restore a model.\n","\n","A model is, abstractly: \n","\n","* A function that computes something on tensors (a **forward pass**)\n","* Some variables that can be updated in response to training\n","\n","In this guide, you will go below the surface of Keras to see how TensorFlow models are defined. This looks at how TensorFlow collects variables and models, as well as how they are saved and restored.\n","\n","Note: If you instead want to immediately get started with Keras, please see [the collection of Keras guides](./keras/).\n"]},{"cell_type":"markdown","source":["TensorFlow에서 기계 학습을 수행하려면 `Model`을 정의, 저장 및 복원해야 할 수 있습니다.\n","\n","모델은 추상적으로 다음과 같습니다.\n","\n","* tensor에서 무언가를 계산하는 함수(forward pass)\n","* 훈련에 대한 응답으로 업데이트될 수 있는 일부 변수\n","\n","이 가이드에서는 TensorFlow 모델이 어떻게 정의되는지 알아보기 위해 Keras 표면 아래로 이동합니다. 여기서는 TensorFlow가 변수와 모델을 수집하는 방법과 저장 및 복원 방법을 살펴봅니다.\n","\n","참고: 대신 Keras를 즉시 시작하려면 Keras 가이드 모음을 참조하세요."],"metadata":{"id":"Ilj61NsjLRSZ"}},{"cell_type":"markdown","metadata":{"id":"VSa6ayJmfZxZ"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:42.182291Z","iopub.status.busy":"2021-10-26T01:29:42.181721Z","iopub.status.idle":"2021-10-26T01:29:43.645213Z","shell.execute_reply":"2021-10-26T01:29:43.645603Z"},"id":"goZwOXp_xyQj","executionInfo":{"status":"ok","timestamp":1675859935297,"user_tz":-540,"elapsed":4942,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["import tensorflow as tf\n","from datetime import datetime\n","\n","%load_ext tensorboard"]},{"cell_type":"markdown","metadata":{"id":"yt5HEbsYAbw1"},"source":["## Defining models and layers in TensorFlow\n","\n","Most models are made of layers. Layers are functions with a known mathematical structure that can be reused and have trainable variables.  In TensorFlow, most high-level implementations of layers and models, such as Keras or [Sonnet](https://github.com/deepmind/sonnet), are built on the same foundational class: `tf.Module`.\n","\n","Here's an example of a very simple `tf.Module` that operates on a scalar tensor:\n"]},{"cell_type":"markdown","source":["대부분의 모델은 layer들로 구성됩니다. layer들은 재사용할 수 있고 학습 가능한 변수가 있는 알려진 수학적 구조를 가진 함수입니다. TensorFlow에서 Keras 또는 Sonnet과 같은 계층 및 모델에 대한 대부분의 고수준 구현은 동일한 기본 클래스인 tf.Module로 만들어집니다.\n","\n","다음은 스칼라 텐서에서 작동하는 매우 간단한 `tf.Module`의 예입니다."],"metadata":{"id":"O7YHOqJOLjm5"}},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.268209Z","iopub.status.busy":"2021-10-26T01:29:44.397917Z","iopub.status.idle":"2021-10-26T01:29:45.280569Z","shell.execute_reply":"2021-10-26T01:29:45.280936Z"},"id":"alhYPVEtAiSy","executionInfo":{"status":"ok","timestamp":1675859955200,"user_tz":-540,"elapsed":535,"user":{"displayName":"서성원","userId":"15488514127948330387"}}},"outputs":[],"source":["class SimpleModule(tf.Module):\n","  def __init__(self, name=None):\n","    super().__init__(name=name)\n","    self.a_variable = tf.Variable(5.0, name=\"train_me\")\n","    self.non_trainable_variable = tf.Variable(5.0, trainable=False, name=\"do_not_train_me\")\n","  def __call__(self, x):\n","    return self.a_variable * x + self.non_trainable_variable"]},{"cell_type":"code","source":["simple_module = SimpleModule(name=\"simple\")\n","\n","simple_module(tf.constant(5.0)) # called __call__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-WbiNPmxNmA","executionInfo":{"status":"ok","timestamp":1675859972559,"user_tz":-540,"elapsed":458,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"74ee76d8-4164-451e-a58e-392944faab5c"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"JwMc_zu5Ant8"},"source":["Modules and, by extension, layers are deep-learning terminology for \"objects\": they have internal state, and methods that use that state.\n","\n","There is nothing special about `__call__` except to act like a [Python callable](https://stackoverflow.com/questions/111234/what-is-a-callable); you can invoke your models with whatever functions you wish.\n","\n","You can set the trainability of variables on and off for any reason, including freezing layers and variables during fine-tuning.\n","\n","Note: **`tf.Module` is the base class for both `tf.keras.layers.Layer` and `tf.keras.Model`, so everything you come across here also applies in Keras.**  For historical compatibility reasons Keras layers do not collect variables from modules, so your models should use only modules or only Keras layers.  However, the methods shown below for inspecting variables are the same in either case.\n","\n","By subclassing `tf.Module`, any `tf.Variable` or `tf.Module` instances assigned to this object's properties are automatically collected.  This allows you to save and load variables, and also create collections of `tf.Module`s."]},{"cell_type":"markdown","source":["모듈과 레이어는 \"객체\"에 대한 딥 러닝 용어입니다. <b>객체는 내부 state와 이러한 state를 사용하는 메서드가 있습니다.</b>\n","\n","Python callable처럼 작동하는 것을 제외하고 `__call__`에 대해 특별한 것은 없습니다. 원하는 함수들로 여러분의 모델을 호출할 수 있습니다.\n","\n","fine-tuning 중 layer 및 변수 freezing을 포함하여 어떤 이유로든 변수의 trainability을 켜고 끌 수 있습니다.\n","\n","참고: tf.Module은 tf.keras.layers.Layer 및 tf.keras.Model의 기본 클래스이므로 여기에서 보는 모든 것이 Keras에도 적용됩니다. <font color=\"blue\"><b>역사적 호환성을 위해 Keras 계층은 module에서 tf.Variables를 수집하지 않으므로 모델은 module만 사용하거나 Keras layer들만 사용해야 합니다. 그러나 아래에 표시된 변수 검사 방법은 두 경우 모두 동일합니다.<b></font>\n","\n","tf.Module을 서브클래싱하면 이 객체의 속성에 할당된 모든 tf.Variable 또는 tf.Module 인스턴스가 자동으로 수집됩니다. 이를 통해 변수를 저장 및 로드하고 tf.Modules 컬렉션을 만들 수도 있습니다."],"metadata":{"id":"ttcGXIWna21Z"}},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.287737Z","iopub.status.busy":"2021-10-26T01:29:45.286884Z","iopub.status.idle":"2021-10-26T01:29:45.291423Z","shell.execute_reply":"2021-10-26T01:29:45.291782Z"},"id":"CyzYy4A_CbVf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675860060728,"user_tz":-540,"elapsed":978,"user":{"displayName":"서성원","userId":"15488514127948330387"}},"outputId":"68e2df0e-69fe-44fd-f9b1-67d999432cbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["trainable variables: (<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>,)\n","************************************************************\n","all variables: (<tf.Variable 'train_me:0' shape=() dtype=float32, numpy=5.0>, <tf.Variable 'do_not_train_me:0' shape=() dtype=float32, numpy=5.0>)\n"]}],"source":["# All trainable variables\n","print(\"trainable variables:\", simple_module.trainable_variables) # trainable_variables는 tf.Module의 속성임. = trainable_variables = a_variable\n","print(\"*\" * 60)\n","# Every variable\n","print(\"all variables:\", simple_module.variables)"]},{"cell_type":"markdown","metadata":{"id":"nuSFrRUNCaaW"},"source":["This is an example of a two-layer linear layer model made out of modules.\n","\n","First a dense (linear) layer:"]},{"cell_type":"markdown","source":["이것은 모듈로 구성된 two-layer linear 모델의 예입니다.\n","\n","먼저 dense(linear) layer:"],"metadata":{"id":"Y49TS8BAcPri"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.296949Z","iopub.status.busy":"2021-10-26T01:29:45.296411Z","iopub.status.idle":"2021-10-26T01:29:45.298647Z","shell.execute_reply":"2021-10-26T01:29:45.298256Z"},"id":"Efb2p2bzAn-V"},"outputs":[],"source":["class Dense(tf.Module):\n","  def __init__(self, in_features, out_features, name=None):\n","    super().__init__(name=name)\n","    self.w = tf.Variable(\n","      tf.random.normal([in_features, out_features]), name='w')\n","    # print(\"self.w=\", self.w)\n","    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n","  def __call__(self, x):\n","    y = tf.matmul(x, self.w) + self.b\n","    return tf.nn.relu(y)"]},{"cell_type":"markdown","metadata":{"id":"bAhMuC-UpnhX"},"source":["And then the complete model, which makes two layer instances and applies them:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.303984Z","iopub.status.busy":"2021-10-26T01:29:45.303461Z","iopub.status.idle":"2021-10-26T01:29:45.697691Z","shell.execute_reply":"2021-10-26T01:29:45.697188Z"},"id":"QQ7qQf-DFw74"},"outputs":[],"source":["class SequentialModule(tf.Module):\n","  def __init__(self, name=None):\n","    super().__init__(name=name)\n","\n","    self.dense_1 = Dense(in_features=3, out_features=3)\n","    self.dense_2 = Dense(in_features=3, out_features=2)\n","\n","  def __call__(self, x):\n","    x = self.dense_1(x)\n","    return self.dense_2(x)"]},{"cell_type":"code","source":["# You have made a model!\n","my_model = SequentialModule(name=\"the_model\")\n","\n","# Call it, with random results\n","print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajvoZ7sm6eXA","executionInfo":{"status":"ok","timestamp":1665103701558,"user_tz":-540,"elapsed":304,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"6bc4e58e-660e-436b-d6d3-ad8e141afda9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model results: tf.Tensor([[0.        2.4882534]], shape=(1, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"d1oUzasJHHXf"},"source":["`tf.Module` instances will automatically collect, recursively, any `tf.Variable` or `tf.Module` instances assigned to it. This allows you to manage collections of `tf.Module`s with a single model instance, and save and load whole models."]},{"cell_type":"markdown","source":["tf.Module 인스턴스는 할당된 모든 tf.Variable 또는 tf.Module 인스턴스를 재귀적으로 자동으로 수집합니다. 이를 통해 단일 모델 인스턴스로 tf.Modules 컬렉션을 관리하고 전체 모델을 저장하고 로드할 수 있습니다."],"metadata":{"id":"m8Zpl4JZdM3Z"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.702840Z","iopub.status.busy":"2021-10-26T01:29:45.702028Z","iopub.status.idle":"2021-10-26T01:29:45.704942Z","shell.execute_reply":"2021-10-26T01:29:45.705320Z"},"id":"JLFA5_PEGb6C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665103807589,"user_tz":-540,"elapsed":291,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"a7476870-390b-45c2-fa91-08ab9ef3075d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Submodules: (<__main__.Dense object at 0x7fde03284150>, <__main__.Dense object at 0x7fde03284490>)\n"]}],"source":["print(\"Submodules:\", my_model.submodules)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.711167Z","iopub.status.busy":"2021-10-26T01:29:45.710473Z","iopub.status.idle":"2021-10-26T01:29:45.716030Z","shell.execute_reply":"2021-10-26T01:29:45.715602Z"},"id":"6lzoB8pcRN12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665103821018,"user_tz":-540,"elapsed":279,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"173013f6-4c60-460f-ee0f-2d161d3f87a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)> \n","\n","<tf.Variable 'w:0' shape=(3, 3) dtype=float32, numpy=\n","array([[-1.3337831 , -0.96477866,  0.95781565],\n","       [ 0.94454396, -1.0532169 ,  0.7352832 ],\n","       [-0.5247758 , -0.7555854 , -0.09246594]], dtype=float32)> \n","\n","<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)> \n","\n","<tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n","array([[ 2.4640367 ,  0.27036673],\n","       [-0.1620068 , -0.81206304],\n","       [-1.2079171 ,  0.7772717 ]], dtype=float32)> \n","\n"]}],"source":["for var in my_model.variables:\n","  print(var, \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"hoaxL3zzm0vK"},"source":["### Waiting to create variables\n","\n","You may have noticed here that you have to define both input and output sizes to the layer.  This is so the `w` variable has a known shape and can be allocated.\n","\n","By deferring variable creation to the first time the module is called with a specific input shape, you do not need specify the input size up front."]},{"cell_type":"markdown","source":["여기서 레이어에 대한 입력 및 출력 크기를 모두 정의해야 한다는 것을 눈치채셨을 것입니다. 이것은 w 변수가 알려진 모양을 갖고 할당될 수 있도록 하기 위한 것입니다.\n","\n","모듈이 특정 입력 형태로 처음 호출될 때 변수 생성을 연기하면 입력 크기를 미리 지정할 필요가 없습니다."],"metadata":{"id":"FoKq8MqEdkrj"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.721887Z","iopub.status.busy":"2021-10-26T01:29:45.721313Z","iopub.status.idle":"2021-10-26T01:29:45.723664Z","shell.execute_reply":"2021-10-26T01:29:45.723259Z"},"id":"XsGCLFXlnPum"},"outputs":[],"source":["class FlexibleDenseModule(tf.Module):\n","  # Note: No need for `in_features`\n","  def __init__(self, out_features, name=None):\n","    super().__init__(name=name)\n","    self.is_built = False\n","    self.out_features = out_features\n","\n","  def __call__(self, x):\n","    print(\"x.shape=\", x.shape)\n","    print(\"x.shape[-1]=\", x.shape[-1])\n","    # Create variables on first call.\n","    if not self.is_built:\n","      self.w = tf.Variable(\n","        tf.random.normal([x.shape[-1], self.out_features]), name='w')\n","      self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n","      self.is_built = True\n","\n","    y = tf.matmul(x, self.w) + self.b\n","    return tf.nn.relu(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.729427Z","iopub.status.busy":"2021-10-26T01:29:45.728695Z","iopub.status.idle":"2021-10-26T01:29:45.734677Z","shell.execute_reply":"2021-10-26T01:29:45.734289Z"},"id":"8bjOWax9LOkP"},"outputs":[],"source":["# Used in a module\n","class MySequentialModule(tf.Module):\n","  def __init__(self, name=None):\n","    super().__init__(name=name)\n","\n","    self.dense_1 = FlexibleDenseModule(out_features=3)\n","    self.dense_2 = FlexibleDenseModule(out_features=2)\n","\n","  def __call__(self, x):\n","    x = self.dense_1(x)\n","    return self.dense_2(x)\n","\n"]},{"cell_type":"code","source":["my_model = MySequentialModule(name=\"the_model\")"],"metadata":{"id":"vREQxuiUgZjC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2r8aBYA_m-a","executionInfo":{"status":"ok","timestamp":1665105079913,"user_tz":-540,"elapsed":285,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"42ed1954-fa09-4e7b-a10f-a2ad4c0e8639"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x.shape= (1, 3)\n","x.shape[-1]= 3\n","x.shape= (1, 3)\n","x.shape[-1]= 3\n","Model results: tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"49JfbhVrpOLH"},"source":["This flexibility is why TensorFlow layers often only need to specify the shape of their outputs, such as in `tf.keras.layers.Dense`, rather than both  the input and output size."]},{"cell_type":"markdown","source":["이러한 유연성 때문에 TensorFlow layer는 종종 입력 및 출력 크기가 아닌 tf.keras.layers.Dense와 같이 출력의 모양만 지정하면 됩니다."],"metadata":{"id":"XDvgH-Lrf3za"}},{"cell_type":"markdown","metadata":{"id":"JOLVVBT8J_dl"},"source":["## Saving weights\n","\n","You can save a `tf.Module` as both a [checkpoint](https://www.tensorflow.org/guide/checkpoint) and a [SavedModel](https://www.tensorflow.org/guide/saved_model).\n","\n","Checkpoints are just the weights (that is, the values of the set of variables inside the module and its submodules):"]},{"cell_type":"markdown","source":["tf.Module을 체크포인트와 저장된 모델로 저장할 수 있습니다.\n","\n","체크포인트는 단지 weight(즉, 모듈과 그 하위 모듈 내부의 변수 집합의 값)입니다."],"metadata":{"id":"qwZS7NEYf-nJ"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.739818Z","iopub.status.busy":"2021-10-26T01:29:45.739291Z","iopub.status.idle":"2021-10-26T01:29:45.745637Z","shell.execute_reply":"2021-10-26T01:29:45.745235Z"},"id":"pHXKRDk7OLHA","outputId":"ed30077d-db88-4640-8459-d6b79c103104","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1665105451468,"user_tz":-540,"elapsed":294,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'my_checkpoint'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["chkp_path = \"my_checkpoint\"\n","checkpoint = tf.train.Checkpoint(model=my_model)\n","checkpoint.write(chkp_path)"]},{"cell_type":"markdown","metadata":{"id":"WXOPMBR4T4ZR"},"source":["Checkpoints consist of two kinds of files: the data itself and an index file for metadata. The index file keeps track of what is actually saved and the numbering of checkpoints, while the checkpoint data contains the variable values and their attribute lookup paths."]},{"cell_type":"markdown","source":["체크포인트는 데이터 자체와 메타데이터용 인덱스 파일의 두 가지 파일로 구성됩니다. 인덱스 파일은 실제로 저장된 항목과 체크포인트의 번호를 추적하는 반면 체크포인트 데이터에는 변수 값과 속성 조회 경로가 포함됩니다."],"metadata":{"id":"Pv9psUMXgh7i"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.749642Z","iopub.status.busy":"2021-10-26T01:29:45.749026Z","iopub.status.idle":"2021-10-26T01:29:45.885158Z","shell.execute_reply":"2021-10-26T01:29:45.885581Z"},"id":"jBV3fprlTWqJ","outputId":"d983937b-29d3-4d57-d752-4c55f68bacee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665105540615,"user_tz":-540,"elapsed":287,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["my_checkpoint.data-00000-of-00001  my_checkpoint.index\n"]}],"source":["!ls my_checkpoint*"]},{"cell_type":"markdown","metadata":{"id":"CowCuBTvXgUu"},"source":["You can look inside a checkpoint to be sure the whole collection of variables is saved, sorted by the Python object that contains them."]},{"cell_type":"markdown","source":["checkpoint 내부를 살펴보고 variables의 전체 컬렉션이 저장되고 variables가 포함된 Python 개체에 따라 정렬되었는지 확인할 수 있습니다."],"metadata":{"id":"706PCRjpgyCT"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.892259Z","iopub.status.busy":"2021-10-26T01:29:45.891493Z","iopub.status.idle":"2021-10-26T01:29:45.894414Z","shell.execute_reply":"2021-10-26T01:29:45.894004Z"},"id":"o2QAdfpvS8tB","outputId":"f5c2dc67-29fc-4c85-f891-0a1de55547f4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665105593160,"user_tz":-540,"elapsed":263,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n"," ('model/dense_1/b/.ATTRIBUTES/VARIABLE_VALUE', [3]),\n"," ('model/dense_1/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 3]),\n"," ('model/dense_2/b/.ATTRIBUTES/VARIABLE_VALUE', [2]),\n"," ('model/dense_2/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 2])]"]},"metadata":{},"execution_count":17}],"source":["tf.train.list_variables(chkp_path)"]},{"cell_type":"markdown","metadata":{"id":"4eGaNiQWcK4j"},"source":["During distributed (multi-machine) training they can be sharded,  which is why they are numbered (e.g., '00000-of-00001').  In this case, though, there is only have one shard.\n","\n","When you load models back in, you overwrite the values in your Python object."]},{"cell_type":"markdown","source":["분산(다중 머신) 학습 중에 샤딩될 수 있으므로 번호가 매겨집니다(예: '00000-of-00001'). 그러나 이 경우에는 하나의 샤드만 있습니다.\n","\n","모델을 다시 로드할 때 Python 객체의 값을 덮어씁니다."],"metadata":{"id":"84D79WNjhBAr"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.900882Z","iopub.status.busy":"2021-10-26T01:29:45.900305Z","iopub.status.idle":"2021-10-26T01:29:45.911874Z","shell.execute_reply":"2021-10-26T01:29:45.912251Z"},"id":"UV8rdDzcwVVg","outputId":"7e9e460d-7ee1-40ea-a040-f2c81e3db1ab","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665105822874,"user_tz":-540,"elapsed":295,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fde029bc710>"]},"metadata":{},"execution_count":18}],"source":["new_model = MySequentialModule()\n","new_checkpoint = tf.train.Checkpoint(model=new_model)\n","new_checkpoint.restore(\"my_checkpoint\")"]},{"cell_type":"code","source":["# Should be the same result as above\n","new_model(tf.constant([[2.0, 2.0, 2.0]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPk7mXQwCe16","executionInfo":{"status":"ok","timestamp":1665105862813,"user_tz":-540,"elapsed":267,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"80150eaf-03ab-4874-b5ba-f29068409273"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x.shape= (1, 3)\n","x.shape[-1]= 3\n","x.shape= (1, 3)\n","x.shape[-1]= 3\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 0.]], dtype=float32)>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"BnPwDRwamdfq"},"source":["Note: As checkpoints are at the heart of long training workflows `tf.checkpoint.CheckpointManager` is a helper class that makes checkpoint management much easier. Refer to the [Training checkpoints guide](https://www.tensorflow.org/guide/checkpoint) for more details."]},{"cell_type":"markdown","source":["참고: 체크포인트는 긴 교육 워크플로의 핵심이므로 tf.checkpoint.CheckpointManager는 체크포인트 관리를 훨씬 쉽게 만드는 도우미 클래스입니다. 자세한 내용은 Training checkpoints guide 를 참조하세요."],"metadata":{"id":"Ec9Vy7YMhvPb"}},{"cell_type":"markdown","metadata":{"id":"pSZebVuWxDXu"},"source":["## Saving `Function`s\n","\n","TensorFlow can run models without the original Python objects, as demonstrated by [TensorFlow Serving](https://tensorflow.org/tfx) and [TensorFlow Lite](https://tensorflow.org/lite), even when you download a trained model from [TensorFlow Hub](https://tensorflow.org/hub).\n","\n","TensorFlow needs to know how to do the computations described in Python, but **without the original code**. To do this, you can make a **graph**, which is described in the [Introduction to graphs and functions guide](./intro_to_graphs.ipynb).\n","\n","This graph contains operations, or *ops*, that implement the function.\n","\n","You can define a graph in the model above by adding the `@tf.function` decorator to indicate that this code should run as a graph."]},{"cell_type":"markdown","source":["TensorFlow Hub에서 사전 훈련된(Pre-Trained) 모델을 다운로드하는 경우에도 TensorFlow Serving 및 TensorFlow Lite에서 설명한 것처럼 TensorFlow는 원본 Python 객체 없이 모델을 실행할 수 있습니다.\n","\n","TensorFlow는 원본 코드 없이 Python으로 작성된 계산을 수행하는 방법을 알아야 합니다. 이를 위해 그래프 및 함수 소개 가이드에 설명된 그래프를 만들 수 있습니다.\n","\n","이 그래프에는 함수를 구현하는 작업 또는 작업이 포함되어 있습니다.\n","\n","이 코드가 그래프로 실행되어야 함을 나타내기 위해 @tf.function 데코레이터를 추가하여 위의 모델에서 그래프를 정의할 수 있습니다."],"metadata":{"id":"HQNXv_gTh79b"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.917955Z","iopub.status.busy":"2021-10-26T01:29:45.917345Z","iopub.status.idle":"2021-10-26T01:29:45.921587Z","shell.execute_reply":"2021-10-26T01:29:45.921157Z"},"id":"WQTvkapUh7lk"},"outputs":[],"source":["class MySequentialModule(tf.Module):\n","  def __init__(self, name=None):\n","    super().__init__(name=name)\n","\n","    self.dense_1 = Dense(in_features=3, out_features=3)\n","    self.dense_2 = Dense(in_features=3, out_features=2)\n","\n","  @tf.function\n","  def __call__(self, x):\n","    print(\"MySequentialModule callable\")\n","    x = self.dense_1(x)\n","    return self.dense_2(x)\n"]},{"cell_type":"code","source":["####################################################\n","# You have made a model with a graph!\n","my_model = MySequentialModule(name=\"the_model\")\n","####################################################"],"metadata":{"id":"IiR_DXVJiOHB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hW66YXBziLo9"},"source":["The module you have made works exactly the same as before.  Each unique signature passed into the function creates a separate graph. Check the [Introduction to graphs and functions guide](./intro_to_graphs.ipynb) for details."]},{"cell_type":"markdown","source":["당신이 만든 모듈은 이전과 정확히 동일하게 작동합니다. 함수에 전달된 각각의 고유한 signature은 별도의 그래프를 생성합니다. 자세한 내용은 그래프 및 함수 소개 가이드를 확인하세요."],"metadata":{"id":"0C_X7uLViVnS"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:45.952803Z","iopub.status.busy":"2021-10-26T01:29:45.940076Z","iopub.status.idle":"2021-10-26T01:29:46.032181Z","shell.execute_reply":"2021-10-26T01:29:46.031731Z"},"id":"H5zUfti3iR52","outputId":"2ca39b73-dae3-4c7a-b820-3a5b1e14e53e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665106227656,"user_tz":-540,"elapsed":287,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 8 calls to <function MySequentialModule.__call__ at 0x7fde029f43b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 9 calls to <function MySequentialModule.__call__ at 0x7fde029f43b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["MySequentialModule callable\n","my_model([[2.0, 2.0, 2.0]])= tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32) \n","\n","MySequentialModule callable\n","my_model([[3.0, 3.0, 3.0]])= tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32) \n","\n","MySequentialModule callable\n","my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]) tf.Tensor(\n","[[[0. 0.]\n","  [0. 0.]]], shape=(1, 2, 2), dtype=float32)\n"]}],"source":["print(\"my_model([[2.0, 2.0, 2.0]])=\", my_model([[2.0, 2.0, 2.0]]), \"\\n\")\n","print(\"my_model([[3.0, 3.0, 3.0]])=\", my_model([[3.0, 3.0, 3.0]]), \"\\n\")\n","print(\"my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]])\", my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))"]},{"cell_type":"code","source":["# print concrete_signatures!!!"],"metadata":{"id":"NJz1sV58FuEv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbGlU1kgyDo7"},"source":["You can visualize the graph by tracing it within a TensorBoard summary."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.038126Z","iopub.status.busy":"2021-10-26T01:29:46.037525Z","iopub.status.idle":"2021-10-26T01:29:46.388182Z","shell.execute_reply":"2021-10-26T01:29:46.388570Z"},"id":"zmy-T67zhp-S","outputId":"09aadd79-25f3-4183-e105-3bafdcadb937","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665106495173,"user_tz":-540,"elapsed":277,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["MySequentialModule callable\n","tf.Tensor([[0.        1.7008992]], shape=(1, 2), dtype=float32)\n"]}],"source":["# Set up logging.\n","stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","logdir = \"logs/func/%s\" % stamp\n","writer = tf.summary.create_file_writer(logdir)\n","\n","# Create a new model to get a fresh trace\n","# Otherwise the summary will not see the graph.\n","new_model = MySequentialModule()\n","\n","# Bracket the function call with\n","# tf.summary.trace_on() and tf.summary.trace_export().\n","tf.summary.trace_on(graph=True)\n","\n","tf.profiler.experimental.start(logdir)\n","# Call only one tf.function when tracing.\n","z = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))\n","with writer.as_default():\n","  tf.summary.trace_export(\n","      name=\"my_func_trace\",\n","      step=0,\n","      profiler_outdir=logdir)"]},{"cell_type":"markdown","metadata":{"id":"gz4lwNZ9hR79"},"source":["Launch TensorBoard to view the resulting trace:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4MXDbgBnkJu","colab":{"base_uri":"https://localhost:8080/","height":820},"executionInfo":{"status":"ok","timestamp":1665106505813,"user_tz":-540,"elapsed":5857,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"b1ee5f22-0272-413c-d323-4aafa50d63ba"},"outputs":[],"source":["#docs_infra: no_execute\n","%tensorboard --logdir logs/func"]},{"cell_type":"markdown","metadata":{"id":"SQu3TVZecmL7"},"source":["### Creating a `SavedModel`\n","\n","The recommended way of sharing completely trained models is to use `SavedModel`.  `SavedModel` contains both a collection of functions and a collection of weights. \n","\n","You can save the model you have just trained as follows:"]},{"cell_type":"markdown","source":["완전히 훈련된 모델을 공유하는 권장 방법은 SavedModel을 사용하는 것입니다. SavedModel에는 함수 컬렉션과 weight 컬렉션이 모두 포함되어 있습니다.\n","\n","방금 훈련한 모델을 다음과 같이 저장할 수 있습니다."],"metadata":{"id":"ZsrUvXP5qE9D"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.397841Z","iopub.status.busy":"2021-10-26T01:29:46.397074Z","iopub.status.idle":"2021-10-26T01:29:46.465961Z","shell.execute_reply":"2021-10-26T01:29:46.465493Z"},"id":"Awv_Tw__WK7a","executionInfo":{"status":"ok","timestamp":1665107377827,"user_tz":-540,"elapsed":336,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8993d79a-b543-44fd-928d-a3e882fc3dfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["MySequentialModule callable\n","MySequentialModule callable\n","MySequentialModule callable\n"]}],"source":["tf.saved_model.save(my_model, \"the_saved_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.484880Z","iopub.status.busy":"2021-10-26T01:29:46.469287Z","iopub.status.idle":"2021-10-26T01:29:46.611657Z","shell.execute_reply":"2021-10-26T01:29:46.611235Z"},"id":"SXv3mEKsefGj","outputId":"0e28502f-b4d0-4881-cdeb-84f8cfefc4a3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665108099919,"user_tz":-540,"elapsed":299,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["total 24\n","drwxr-xr-x 2 root root  4096 Oct  7 01:49 assets\n","-rw-r--r-- 1 root root 15989 Oct  7 01:49 saved_model.pb\n","drwxr-xr-x 2 root root  4096 Oct  7 01:49 variables\n"]}],"source":["# Inspect the SavedModel in the directory\n","!ls -l the_saved_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.630647Z","iopub.status.busy":"2021-10-26T01:29:46.629916Z","iopub.status.idle":"2021-10-26T01:29:46.756827Z","shell.execute_reply":"2021-10-26T01:29:46.756278Z"},"id":"vQQ3hEvHYdoR","outputId":"45fdf8a2-dfdd-40aa-b394-7617d114b349","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665108122678,"user_tz":-540,"elapsed":270,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["total 8\n","-rw-r--r-- 1 root root 456 Oct  7 01:49 variables.data-00000-of-00001\n","-rw-r--r-- 1 root root 356 Oct  7 01:49 variables.index\n"]}],"source":["# The variables/ directory contains a checkpoint of the variables \n","!ls -l the_saved_model/variables"]},{"cell_type":"markdown","metadata":{"id":"xBqPop7ZesBU"},"source":["The `saved_model.pb` file is a [protocol buffer](https://developers.google.com/protocol-buffers) describing the functional `tf.Graph`.\n","\n","Models and layers can be loaded from this representation without actually making an instance of the class that created it.  This is desired in situations where you do not have (or want) a Python interpreter, such as serving at scale or on an edge device, or in situations where the original Python code is not available or practical to use.\n","\n","You can load the model as new object:"]},{"cell_type":"markdown","source":["<font color=\"red\">saved_model.pb 파일은 functional tf.Graph를 설명하는 프로토콜 버퍼입니다.</font>\n","\n","모델과 레이어는 실제로 모델을 생성시킨 클래스의 인스턴스를 만들지 않고도 이 represent에서 로드될 수 있습니다. 이는 대규모 또는 에지 장치에서 제공하는 것과 같이 Python 인터프리터가 없거나 원하지 않는 상황이나 원래 Python 코드를 사용할 수 없거나 사용할 수 없는 상황에서 바람직합니다.\n","\n","모델을 새로운 객체로 로드할 수 있습니다."],"metadata":{"id":"Yuup2w5VqYb7"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.762958Z","iopub.status.busy":"2021-10-26T01:29:46.761343Z","iopub.status.idle":"2021-10-26T01:29:46.794996Z","shell.execute_reply":"2021-10-26T01:29:46.794546Z"},"id":"zRFcA5wIefv4"},"outputs":[],"source":["new_model = tf.saved_model.load(\"the_saved_model\")"]},{"cell_type":"markdown","metadata":{"id":"-9EF3mT7i3qN"},"source":["`new_model`, created from loading a saved model, is an internal TensorFlow user object without any of the class knowledge. It is not of type `SequentialModule`."]},{"cell_type":"markdown","source":["<font color=\"red\">**저장된 모델을 로드하여 생성된 `new_model`은 클래스 지식이 없는 내부 TensorFlow 유저 객체입니다. SequentialModule 유형이 아닙니다.**</font>"],"metadata":{"id":"YB-AXzBQtKez"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.799876Z","iopub.status.busy":"2021-10-26T01:29:46.799115Z","iopub.status.idle":"2021-10-26T01:29:46.801761Z","shell.execute_reply":"2021-10-26T01:29:46.802103Z"},"id":"EC_eQj7yi54G","outputId":"10bda7fe-d706-42bc-e1bd-158e4725ba02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665108744559,"user_tz":-540,"elapsed":283,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":33}],"source":["isinstance(new_model, SequentialModule)"]},{"cell_type":"markdown","metadata":{"id":"-OrOX1zxiyhR"},"source":["This new model works on the already-defined input signatures. You can't add more signatures to a model restored like this."]},{"cell_type":"markdown","source":["이 새 모델은 이미 정의된 입력 signatures에서 작동합니다. 이렇게 복원된 모델에는 signatures을 더 추가할 수 없습니다."],"metadata":{"id":"5zEVSD86tpOk"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.806327Z","iopub.status.busy":"2021-10-26T01:29:46.805740Z","iopub.status.idle":"2021-10-26T01:29:46.810565Z","shell.execute_reply":"2021-10-26T01:29:46.810113Z"},"id":"_23BYYBWfKnc","outputId":"e82bf43a-b6f6-441e-b4a4-2933c3c2d6ca","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665108863039,"user_tz":-540,"elapsed":485,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n","tf.Tensor(\n","[[[0. 0.]\n","  [0. 0.]]], shape=(1, 2, 2), dtype=float32)\n"]}],"source":["print(new_model([[2.0, 2.0, 2.0]]))\n","print(new_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))"]},{"cell_type":"code","source":["print(new_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":686},"id":"9iyz-mHwtzYK","executionInfo":{"status":"error","timestamp":1665108866418,"user_tz":-540,"elapsed":742,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"73f17a6b-7568-4d3c-bcd7-295236bb6a27"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-38aa62330f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m           .format(index + 1, _pretty_format_positional(positional), keyword))\n\u001b[1;32m    283\u001b[0m     raise ValueError(\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;34m\"Could not find matching concrete function to call loaded from the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;34mf\"SavedModel. Got:\\n  {_pretty_format_positional(args)}\\n  Keyword \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;34mf\"arguments: {kwargs}\\n\\n Expected these arguments to match one of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Could not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (1 total):\n    * [[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 3 option(s):\n\nOption 1:\n  Positional arguments (1 total):\n    * [[2.0, 2.0, 2.0]]\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (1 total):\n    * [[3.0, 3.0, 3.0]]\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (1 total):\n    * [[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]\n  Keyword arguments: {}"]}]},{"cell_type":"markdown","metadata":{"id":"qSFhoMtTjSR6"},"source":["Thus, using `SavedModel`, you are able to save TensorFlow weights and graphs using `tf.Module`, and then load them again."]},{"cell_type":"markdown","source":["따라서 SavedModel을 사용하면 tf.Module을 사용하여 TensorFlow weight와 그래프를 저장하고 다시 로드할 수 있습니다."],"metadata":{"id":"gF9-I5HcuCE2"}},{"cell_type":"markdown","metadata":{"id":"Rb9IdN7hlUZK"},"source":["## Keras models and layers\n","\n","Note that up until this point, there is no mention of Keras. You can build your own high-level API on top of `tf.Module`, and people have.  \n","\n","In this section, you will examine how Keras uses `tf.Module`.  A complete user guide to Keras models can be found in the [Keras guide](https://www.tensorflow.org/guide/keras/sequential_model).\n"]},{"cell_type":"markdown","source":["여기까지는 Keras에 대한 언급이 없습니다. tf.Module 위에 여러분만의 고수준 API를 구축할 수 있습니다\n","\n","이 섹션에서는 Keras가 tf.Module을 사용하는 방법을 살펴봅니다. Keras 모델에 대한 전체 사용자 가이드는 Keras 가이드에서 찾을 수 있습니다."],"metadata":{"id":"nzJ8iWqbuH0m"}},{"cell_type":"markdown","metadata":{"id":"uigsVGPreE-D"},"source":["### Keras layers\n","\n","`tf.keras.layers.Layer` is the base class of all Keras layers, and it inherits from `tf.Module`.\n","\n","You can convert a module into a Keras layer just by swapping out the parent and then changing `__call__` to `call`:"]},{"cell_type":"markdown","source":["tf.keras.layers.Layer는 모든 Keras 계층의 기본 클래스이며 tf.Module에서 상속됩니다.\n","\n","`tf.Module` 상속을 `tf.keras.layers.Layer` 상속으로 교체한 다음 기존 `__call__` 함수를 `call` 함수로 변경하여 tf.Module을 Keras Layer로 변환할 수 있습니다."],"metadata":{"id":"5Ri-MqfGubU7"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.816256Z","iopub.status.busy":"2021-10-26T01:29:46.815683Z","iopub.status.idle":"2021-10-26T01:29:46.958760Z","shell.execute_reply":"2021-10-26T01:29:46.959157Z"},"id":"88YOGquhnQRd"},"outputs":[],"source":["class MyDense(tf.keras.layers.Layer):\n","  # Adding **kwargs to support base Keras layer arguments\n","  def __init__(self, in_features, out_features, **kwargs):\n","    super().__init__(**kwargs)\n","\n","    # This will soon move to the build step; see below\n","    self.w = tf.Variable(\n","      tf.random.normal([in_features, out_features]), name='w')\n","    self.b = tf.Variable(tf.zeros([out_features]), name='b')\n","  def call(self, x):\n","    y = tf.matmul(x, self.w) + self.b\n","    return tf.nn.relu(y)"]},{"cell_type":"code","source":["simple_layer = MyDense(name=\"simple\", in_features=3, out_features=3)"],"metadata":{"id":"_hpwhOKOPEWs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nYGmAsPrws--"},"source":["Keras layers have their own `__call__` that does some bookkeeping described in the next section and then calls `call()`. You should notice no change in functionality."]},{"cell_type":"markdown","source":["Keras 레이어에는 다음 섹션에서 설명하는 일부 bookkeeping를 수행한 다음 call()을 호출하는 자체 __call__ 함수가 있습니다. 기능에 변화가 없음을 알 수 있습니다."],"metadata":{"id":"dllS2JQYvosM"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.964307Z","iopub.status.busy":"2021-10-26T01:29:46.963684Z","iopub.status.idle":"2021-10-26T01:29:46.968726Z","shell.execute_reply":"2021-10-26T01:29:46.969125Z"},"id":"nIqE8wOznYKG","outputId":"811a2b4d-4123-42ef-f9b1-be9d65d48b50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665109105285,"user_tz":-540,"elapsed":275,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.67874813, 4.032743  , 3.017374  ]], dtype=float32)>"]},"metadata":{},"execution_count":40}],"source":["simple_layer([[2.0, 2.0, 2.0]])"]},{"cell_type":"markdown","metadata":{"id":"tmN5vb1K18U1"},"source":["### The `build` step\n","\n","As noted, it's convenient in many cases to wait to create variables until you are sure of the input shape.\n","\n","Keras layers come with an extra lifecycle step that allows you more flexibility in how you define your layers. This is defined in the `build` function.\n","\n","`build` is called exactly once, and it is called with the shape of the input. It's usually used to create variables (weights).\n","\n","You can rewrite `MyDense` layer above to be flexible to the size of its inputs:\n"]},{"cell_type":"markdown","source":["언급했듯이 입력 형태가 확실할 때까지 변수 생성을 기다리는 것이 많은 경우에 편리합니다.\n","\n","Keras 레이어에는 레이어를 정의하는 방법에 더 많은 유연성을 제공하는 추가 lifecycle 단계가 있습니다. 이것은 빌드 함수에서 정의됩니다.\n","\n","build 는 정확히 한 번 호출되며 입력의 shape으로 호출됩니다. 일반적으로 변수(weigth)를 만드는 데 사용됩니다.\n","\n","위의 MyDense 레이어를 다시 작성하여 입력 크기에 유연하게 맞출 수 있습니다."],"metadata":{"id":"nB2BVRF3v8-E"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.975960Z","iopub.status.busy":"2021-10-26T01:29:46.975203Z","iopub.status.idle":"2021-10-26T01:29:46.977277Z","shell.execute_reply":"2021-10-26T01:29:46.977620Z"},"id":"4YTfrlgdsURp"},"outputs":[],"source":["class FlexibleDense(tf.keras.layers.Layer):\n","  # Note the added `**kwargs`, as Keras supports many arguments\n","  def __init__(self, out_features, **kwargs):\n","    super().__init__(**kwargs)\n","    self.out_features = out_features\n","\n","  def build(self, input_shape):  # Create the state of the layer (weights)\n","    print(\"called FlexibleDense::build\")\n","    self.w = tf.Variable(\n","      tf.random.normal([input_shape[-1], self.out_features]), name='w')\n","    self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n","\n","  def call(self, inputs):  # Defines the computation from inputs to outputs\n","    print(\"called FlexibleDense::call\")\n","    return tf.matmul(inputs, self.w) + self.b\n","\n"]},{"cell_type":"code","source":["# Create the instance of the layer\n","flexible_dense = FlexibleDense(out_features=3)"],"metadata":{"id":"gt15TIodwWvk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Koc_uSqt2PRh"},"source":["At this point, the model has not been built, so there are no variables:"]},{"cell_type":"markdown","source":["이 시점에서 모델이 빌드되지 않았으므로 변수가 없습니다."],"metadata":{"id":"CUrdHQy8wdDP"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.982040Z","iopub.status.busy":"2021-10-26T01:29:46.981334Z","iopub.status.idle":"2021-10-26T01:29:46.984346Z","shell.execute_reply":"2021-10-26T01:29:46.983816Z"},"id":"DgyTyUD32Ln4","outputId":"a5cc2632-a8b8-4e15-b9e6-0c55bcb2ef12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665109199080,"user_tz":-540,"elapsed":299,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":43}],"source":["flexible_dense.variables"]},{"cell_type":"markdown","metadata":{"id":"-KdamIVl2W8Y"},"source":["Calling the function allocates appropriately-sized variables:"]},{"cell_type":"markdown","source":["함수[call()]를 호출하면 적절한 크기의 변수가 할당됩니다."],"metadata":{"id":"7pWARIahwjOk"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.988677Z","iopub.status.busy":"2021-10-26T01:29:46.988076Z","iopub.status.idle":"2021-10-26T01:29:46.992567Z","shell.execute_reply":"2021-10-26T01:29:46.992917Z"},"id":"IkLyEx7uAoTK","outputId":"813f5553-6a4d-4e7e-ba41-5846986671c3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665109265123,"user_tz":-540,"elapsed":276,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["called FlexibleDense::build\n","called FlexibleDense::call\n","Model results: tf.Tensor(\n","[[-0.778502   3.9722497 -1.746544 ]\n"," [-1.167753   5.9583745 -2.6198156]], shape=(2, 3), dtype=float32)\n"]}],"source":["# Call it, with predictably random results\n","print(\"Model results:\", flexible_dense(tf.constant([[2.0, 2.0, 2.0], [3.0, 3.0, 3.0]])))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:46.996831Z","iopub.status.busy":"2021-10-26T01:29:46.996160Z","iopub.status.idle":"2021-10-26T01:29:47.000909Z","shell.execute_reply":"2021-10-26T01:29:47.001380Z"},"id":"Swofpkrd2YDd","outputId":"091a8224-9b42-4c11-f083-32198d5e6187","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665109313175,"user_tz":-540,"elapsed":270,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Variable 'flexible_dense/w:0' shape=(3, 3) dtype=float32, numpy=\n"," array([[ 1.0096889 ,  0.5873897 ,  0.0836022 ],\n","        [-0.7073977 ,  1.4682889 , -1.4798621 ],\n","        [-0.69154215, -0.06955379,  0.5229879 ]], dtype=float32)>,\n"," <tf.Variable 'flexible_dense/b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"]},"metadata":{},"execution_count":45}],"source":["flexible_dense.variables"]},{"cell_type":"markdown","metadata":{"id":"7PuNUnf0OIpF"},"source":["Since `build` is only called once, inputs will be rejected if the input shape is not compatible with the layer's variables:"]},{"cell_type":"markdown","source":["`build`는 한 번만 호출되므로 input shape이 레이어의 variables와 호환되지 않으면 입력이 거부됩니다."],"metadata":{"id":"e2wj_ZZTw2HU"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.006006Z","iopub.status.busy":"2021-10-26T01:29:47.005344Z","iopub.status.idle":"2021-10-26T01:29:47.008344Z","shell.execute_reply":"2021-10-26T01:29:47.008729Z"},"id":"caYWDrHSAy_j","outputId":"eeae8818-6924-4ca1-b011-7cc7fab50ba2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665109409420,"user_tz":-540,"elapsed":308,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["called FlexibleDense::call\n","Failed: Exception encountered when calling layer \"flexible_dense\" (type FlexibleDense).\n","\n","Matrix size-incompatible: In[0]: [1,4], In[1]: [3,3] [Op:MatMul]\n","\n","Call arguments received:\n","  • inputs=tf.Tensor(shape=(1, 4), dtype=float32)\n"]}],"source":["try:\n","  print(\"Model results:\", flexible_dense(tf.constant([[2.0, 2.0, 2.0, 2.0]])))\n","except tf.errors.InvalidArgumentError as e:\n","  print(\"Failed:\", e)"]},{"cell_type":"markdown","metadata":{"id":"YnporXiudF1I"},"source":["Keras layers have a lot more extra features including:\n","\n","* Optional losses\n","* Support for metrics\n","* Built-in support for an optional `training` argument to differentiate between training and inference use\n","* `get_config` and `from_config` methods that allow you to accurately store configurations to allow model cloning in Python\n","\n","Read about them in the [full guide](./keras/custom_layers_and_models.ipynb) to custom layers and models."]},{"cell_type":"markdown","source":["Keras 레이어에는 다음과 같은 훨씬 더 많은 추가 기능이 있습니다.\n","\n","* 선택할 수 있는 여러 loss 지원\n","* metric 지원\n","* training과 inference 사용을 구별하기 위한 선택적 training argument에 대한 내장 지원\n","* Python에서 모델 복제를 허용하도록 configuration을 정확하게 저장할 수 있는 get_config 및 from_config 메서드\n","\n","사용자 지정 계층 및 모델에 대한 전체 가이드에서 이에 대해 읽어보세요."],"metadata":{"id":"ih0AkkIRxcoe"}},{"cell_type":"markdown","metadata":{"id":"L2kds2IHw2KD"},"source":["### Keras models\n","\n","You can define your model as nested Keras layers.\n","\n","However, Keras also provides a full-featured model class called `tf.keras.Model`. It inherits from `tf.keras.layers.Layer`, so a Keras model can be used, nested, and saved in the same way as Keras layers. Keras models come with extra functionality that makes them easy to train, evaluate, load, save, and even train on multiple machines.\n","\n","You can define the `SequentialModule` from above with nearly identical code, again converting `__call__` to `call()` and changing the parent:"]},{"cell_type":"markdown","source":["모델을 중첩된 Keras 레이어로 정의할 수 있습니다.\n","\n","그러나 Keras는 tf.keras.Model이라는 완전한 기능을 갖춘 모델 클래스도 제공합니다. tf.keras.layers.Layer에서 상속하므로 Keras.Model을 Keras.Layer와 동일한 방식으로 사용, 중첩 및 저장할 수 있습니다. Keras.Model에는 여러 머신에서 쉽게 훈련, 평가, 로드, 저장 및 훈련할 수 있는 추가 기능이 있습니다.\n","\n","위와 거의 동일한 코드로 SequentialModule을 정의할 수 있습니다. 다시 `__call__`을 `call()`으로 변환하고 부모를 변경합니다."],"metadata":{"id":"HwqPLjXWyI98"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.015380Z","iopub.status.busy":"2021-10-26T01:29:47.014737Z","iopub.status.idle":"2021-10-26T01:29:47.025222Z","shell.execute_reply":"2021-10-26T01:29:47.025610Z"},"id":"Hqjo1DiyrHrn"},"outputs":[],"source":["class MySequentialModel(tf.keras.Model):\n","  def __init__(self, name=None, **kwargs):\n","    super().__init__(**kwargs)\n","\n","    self.dense_1 = FlexibleDense(out_features=3)\n","    self.dense_2 = FlexibleDense(out_features=2)\n","  def call(self, x):\n","    x = self.dense_1(x)\n","    return self.dense_2(x)"]},{"cell_type":"code","source":["# You have made a Keras model!\n","my_sequential_model = MySequentialModel(name=\"the_model\")\n","\n","# Call it on a tensor, with random results\n","print(\"Model results:\", my_sequential_model(tf.constant([[2.0, 2.0, 2.0]])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pvNaSOyyuFV","executionInfo":{"status":"ok","timestamp":1665109979281,"user_tz":-540,"elapsed":2,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"53027f65-2b8e-4226-8790-c19eae2cb61e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["called FlexibleDense::build\n","called FlexibleDense::call\n","called FlexibleDense::build\n","called FlexibleDense::call\n","Model results: tf.Tensor([[3.6755495 3.989869 ]], shape=(1, 2), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"8i-CR_h2xw3z"},"source":["All the same features are available, including tracking variables and submodules.\n","\n","Note: To emphasize the note above, a raw `tf.Module` nested inside a Keras layer or model will not get its variables collected for training or saving.  Instead, nest Keras layers inside of Keras layers."]},{"cell_type":"markdown","source":["tracking 변수 및 하위 모듈을 포함하여 모든 동일한 기능을 사용할 수 있습니다.\n","\n","참고: 위의 참고 사항을 강조하기 위해 Keras.layer 또는 keras.modle 내부에 중첩된 raw tf.Module은 학습 또는 저장을 위해 수집된 변수를 가져오지 않습니다. 대신 Keras 레이어 내부에 Keras 레이어를 중첩합니다."],"metadata":{"id":"oL4QXrwnzBEb"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.030143Z","iopub.status.busy":"2021-10-26T01:29:47.029565Z","iopub.status.idle":"2021-10-26T01:29:47.035457Z","shell.execute_reply":"2021-10-26T01:29:47.035025Z"},"id":"hdLQFNdMsOz1","outputId":"756488c0-803e-4a62-9afc-239ecbc33079","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665110015789,"user_tz":-540,"elapsed":475,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Variable 'my_sequential_model/flexible_dense_1/w:0' shape=(3, 3) dtype=float32, numpy=\n"," array([[ 0.55456114, -0.08233272,  0.44348752],\n","        [ 0.16435763, -1.0189123 ,  0.12058347],\n","        [-0.59768844,  1.1908588 ,  0.60987145]], dtype=float32)>,\n"," <tf.Variable 'my_sequential_model/flexible_dense_1/b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n"," <tf.Variable 'my_sequential_model/flexible_dense_2/w:0' shape=(3, 2) dtype=float32, numpy=\n"," array([[2.0176234 , 0.80732167],\n","        [0.320094  , 0.17715621],\n","        [1.3326826 , 1.6024525 ]], dtype=float32)>,\n"," <tf.Variable 'my_sequential_model/flexible_dense_2/b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"]},"metadata":{},"execution_count":49}],"source":["my_sequential_model.variables"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.041140Z","iopub.status.busy":"2021-10-26T01:29:47.040512Z","iopub.status.idle":"2021-10-26T01:29:47.043803Z","shell.execute_reply":"2021-10-26T01:29:47.043280Z"},"id":"JjVAMrAJsQ7G","outputId":"4f49fddb-efc8-43d1-8a26-d3baac3607f6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665110024374,"user_tz":-540,"elapsed":283,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<__main__.FlexibleDense at 0x7fde00e40d90>,\n"," <__main__.FlexibleDense at 0x7fde00e403d0>)"]},"metadata":{},"execution_count":50}],"source":["my_sequential_model.submodules"]},{"cell_type":"markdown","metadata":{"id":"FhP8EItC4oac"},"source":["Overriding `tf.keras.Model` is a very Pythonic approach to building TensorFlow models.  If you are migrating models from other frameworks, this can be very straightforward.\n","\n","If you are constructing models that are simple assemblages of existing layers and inputs, you can save time and space by using the [functional API](./keras/functional.ipynb), which comes with additional features around model reconstruction and architecture.\n","\n","Here is the same model with the functional API:"]},{"cell_type":"markdown","source":["tf.keras.Model을 overriding하는 것은 TensorFlow 모델 구축에 대한 매우 Pythonic한 접근 방식입니다. 다른 프레임워크에서 모델을 마이그레이션하는 경우 매우 간단할 수 있습니다.\n","\n","기존 레이어와 입력의 단순한 조합인 모델을 구성하는 경우 모델 재구성 및 아키텍처와 관련된 추가 기능과 함께 제공되는 `functional API`를 사용하여 시간과 공간을 절약할 수 있습니다.\n","\n","다음은 `functional API`가 있는 동일한 모델입니다."],"metadata":{"id":"M9wTqw4fzigy"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.052158Z","iopub.status.busy":"2021-10-26T01:29:47.051385Z","iopub.status.idle":"2021-10-26T01:29:47.094959Z","shell.execute_reply":"2021-10-26T01:29:47.094531Z"},"id":"jJiZZiJ0fyqQ","outputId":"fa71e0c1-8589-4e18-de0c-7c2f0b1af881","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665110838083,"user_tz":-540,"elapsed":291,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["called FlexibleDense::build\n","called FlexibleDense::call\n","x type= <class 'keras.engine.keras_tensor.KerasTensor'>\n","called FlexibleDense::build\n","called FlexibleDense::call\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 3)]               0         \n","                                                                 \n"," flexible_dense_5 (FlexibleD  (None, 3)                12        \n"," ense)                                                           \n","                                                                 \n"," flexible_dense_6 (FlexibleD  (None, 2)                8         \n"," ense)                                                           \n","                                                                 \n","=================================================================\n","Total params: 20\n","Trainable params: 20\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inputs = tf.keras.Input(shape=[3,])\n","\n","x = FlexibleDense(3)(inputs)\n","print(\"x type=\", type(x))\n","x = FlexibleDense(2)(x)\n","\n","####\n","my_functional_model = tf.keras.Model(inputs=inputs, outputs=x)\n","\n","my_functional_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.100143Z","iopub.status.busy":"2021-10-26T01:29:47.099540Z","iopub.status.idle":"2021-10-26T01:29:47.105134Z","shell.execute_reply":"2021-10-26T01:29:47.104655Z"},"id":"kg-xAZw5gaG6","outputId":"6d6e0d00-9411-4bbd-a685-72d3ba2ab7cf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665110843255,"user_tz":-540,"elapsed":289,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["called FlexibleDense::call\n","called FlexibleDense::call\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[3.7929738, 4.7242155]], dtype=float32)>"]},"metadata":{},"execution_count":53}],"source":["my_functional_model(tf.constant([[2.0, 2.0, 2.0]]))"]},{"cell_type":"markdown","metadata":{"id":"s_BK9XH5q9cq"},"source":["The major difference here is that the input shape is specified up front as part of the functional construction process. The `input_shape` argument in this case does not have to be completely specified; you can leave some dimensions as `None`.\n","\n","Note: You do not need to specify `input_shape` or an `InputLayer` in a subclassed model; these arguments and layers will be ignored."]},{"cell_type":"markdown","source":["여기서 주요 차이점은 입력 shape이 기능 구성 프로세스의 일부로 미리 지정된다는 것입니다. 이 경우 input_shape 인수를 완전히 지정할 필요는 없습니다. 일부 demension는 None으로 둘 수 있습니다.\n","\n","참고: 서브클래싱된 모델에서는 input_shape 또는 InputLayer를 지정할 필요가 없습니다. 이러한 인수와 레이어는 무시됩니다."],"metadata":{"id":"MVqd8jhQ2Qe8"}},{"cell_type":"markdown","metadata":{"id":"qI9aXLnaHEFF"},"source":["## Saving Keras models\n","\n","Keras models can be checkpointed, and that will look the same as `tf.Module`.\n","\n","Keras models can also be saved with `tf.saved_model.save()`, as they are modules.  However, Keras models have convenience methods and other functionality:"]},{"cell_type":"markdown","source":["Keras 모델은 checkpoint을 지정할 수 있으며 이는 tf.Module과 동일하게 보입니다.\n","\n","Keras 모델은 모듈이므로 tf.saved_model.save()로 저장할 수도 있습니다. 그러나 Keras 모델에는 편리한 방법 및 기타 기능이 있습니다."],"metadata":{"id":"pWg75v682gGa"}},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.114444Z","iopub.status.busy":"2021-10-26T01:29:47.110555Z","iopub.status.idle":"2021-10-26T01:29:47.413172Z","shell.execute_reply":"2021-10-26T01:29:47.413591Z"},"id":"SAz-KVZlzAJu","outputId":"ceef2caf-6469-46f9-b12c-ec2154bba0da","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665110854458,"user_tz":-540,"elapsed":627,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["called FlexibleDense::call\n","called FlexibleDense::call\n","called FlexibleDense::call\n","called FlexibleDense::call\n","called FlexibleDense::call\n","called FlexibleDense::call\n","called FlexibleDense::call\n","called FlexibleDense::call\n"]}],"source":["my_sequential_model.save(\"exname_of_file\")"]},{"cell_type":"markdown","metadata":{"id":"C2urAeR-omns"},"source":["Just as easily, they can be loaded back in:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.418144Z","iopub.status.busy":"2021-10-26T01:29:47.417583Z","iopub.status.idle":"2021-10-26T01:29:47.498029Z","shell.execute_reply":"2021-10-26T01:29:47.497579Z"},"id":"Wj5DW-LCopry","outputId":"27c4b167-2f9e-495a-f351-6ba73fac78e1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665110872315,"user_tz":-540,"elapsed":380,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]}],"source":["reconstructed_model = tf.keras.models.load_model(\"exname_of_file\")"]},{"cell_type":"markdown","metadata":{"id":"EA7P_MNvpviZ"},"source":["Keras `SavedModels` also save metric, loss, and optimizer states.\n","\n","This reconstructed model can be used and will produce the same result when called on the same data:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-10-26T01:29:47.505115Z","iopub.status.busy":"2021-10-26T01:29:47.502458Z","iopub.status.idle":"2021-10-26T01:29:47.521630Z","shell.execute_reply":"2021-10-26T01:29:47.521175Z"},"id":"P_wGfQo5pe6T","outputId":"762917b0-68a1-44d2-f2c6-362e525f6411","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665110879336,"user_tz":-540,"elapsed":264,"user":{"displayName":"서성원","userId":"03248215396884205789"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[3.6755495, 3.989869 ]], dtype=float32)>"]},"metadata":{},"execution_count":56}],"source":["reconstructed_model(tf.constant([[2.0, 2.0, 2.0]]))"]},{"cell_type":"markdown","metadata":{"id":"xKyjlkceqjwD"},"source":["There is more to know about saving and serialization of Keras models, including providing configuration methods for custom layers for feature support. Check out the [guide to saving and serialization](https://www.tensorflow.org/guide/keras/save_and_serialize)."]},{"cell_type":"markdown","metadata":{"id":"kcdMMPYv7Krz"},"source":["# What's next\n","\n","If you want to know more details about Keras, you can follow the existing Keras guides [here](./keras/).\n","\n","Another example of a high-level API built on `tf.module` is Sonnet from DeepMind, which is covered on [their site](https://github.com/deepmind/sonnet)."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"nbformat":4,"nbformat_minor":0}